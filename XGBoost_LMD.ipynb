{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##AnomalyDetection with XGBoost\n",
        "\n",
        "This cell loads the dataset, selects relevant columns. It defines lists of categorical and numerical columns for further processing, and initializes variables for cross-validation.\n",
        "\n",
        "The chosen feautures were seen to be the 10 most important in SHAP explanation using IsolationForest ML technique."
      ],
      "metadata": {
        "id": "26cOhjpx3H_I"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SivqoRqZs1R1",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split,StratifiedShuffleSplit, GridSearchCV\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
        "import xgboost as xgb\n",
        "from xgboost.sklearn import XGBClassifier\n",
        "\n",
        "\n",
        "x = pd.read_csv(\"/content/drive/MyDrive/data/LMD-2023 [1.75M Elements][Labelled]checked.csv\",low_memory=False)\n",
        "\n",
        "cols = ['DestinationPortName','EventID','ThreadID','Computer','EventRecordID','Initiated',\n",
        "        'ProcessId','SourcePort', 'DestinationPort','Execution_ProcessID','Label']\n",
        "\n",
        "x = x[cols]\n",
        "\n",
        "y = x['Label'].copy()\n",
        "y = np.where(y > 0, 1, 0) # 1 means outlier\n",
        "\n",
        "x = x.drop(columns=['Label'])\n",
        "\n",
        "\n",
        "categorical_cols = ['Computer', 'DestinationPortName', 'EventID', 'Initiated']\n",
        "\n",
        "numerical_cols = ['EventRecordID','Execution_ProcessID', 'ProcessId','ThreadID','SourcePort','DestinationPort']\n",
        "\n",
        "x_orig = pd.concat([x[categorical_cols], x[numerical_cols]], axis=1)\n",
        "\n",
        "encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
        "\n",
        "encoder.fit(x[categorical_cols])\n",
        "\n",
        "x_categorial = pd.DataFrame(encoder.transform(x[categorical_cols]),\n",
        "                                columns=encoder.get_feature_names_out(categorical_cols),\n",
        "                                index=x.index)\n",
        "\n",
        "\n",
        "x = pd.concat([x_categorial, x[numerical_cols]], axis=1)\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=1,stratify=y)\n",
        "\n",
        "\n",
        "x_train_categorial = x_train[x_categorial.columns]\n",
        "x_test_categorial = x_test[x_categorial.columns]\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(x_train[numerical_cols])\n",
        "\n",
        "train_num_scaled = pd.DataFrame(scaler.transform(x_train[numerical_cols]), columns=numerical_cols, index=x_train.index)\n",
        "test_num_scaled = pd.DataFrame(scaler.transform(x_test[numerical_cols]), columns=numerical_cols, index=x_test.index)\n",
        "\n",
        "\n",
        "x_train = pd.concat([x_train_categorial, train_num_scaled], axis=1)\n",
        "x_test = pd.concat([x_test_categorial, test_num_scaled], axis=1)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tunning Prameters:\n",
        "In order to decide on boosting parameters, we need to set some initial values of other parameters. Let’s take the following values:\n",
        "\n",
        "max_depth = 5: This should be between 3-10, I’ve started with 5.\n",
        "\n",
        "min_child_weight = 1: A smaller value is chosen because it is a highly imbalanced class problem, and leaf nodes can have smaller size groups.\n",
        "\n",
        "gamma = 0.2: A smaller value like 0.1-0.2 can also be chosen for starting. This will, anyways, be tuned later.\n",
        "\n",
        "subsample, colsample_bytree = 0.5: This is a commonly used start value. Typical values range between 0.5-0.9.\n",
        "\n",
        "scale_pos_weight = 1: Because of high-class imbalance.\n",
        "\n",
        "Please note that all the above are just initial estimates and will be tuned later.\n",
        "\n",
        "##Tunning n_estimators parameter:\n",
        "Let’s take the learning rate of 0.001 here and check the optimum number of trees using the cross validation technique.\n"
      ],
      "metadata": {
        "id": "J7OVLIxY3aeq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_yU6woOXoXW",
        "outputId": "ed81521e-7fb0-44e9-d3f6-c4121c6f1b62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'n_estimators': 900}\n",
            "Best Score: 0.8707113400355556\n"
          ]
        }
      ],
      "source": [
        "# Define the hyperparameter grid\n",
        "param_grid = {\n",
        "    'n_estimators': [i for i in range(100,1000,100)],\n",
        "}\n",
        "\n",
        "# Initialize Isolation Forest model\n",
        "xgb1 = XGBClassifier(\n",
        "    n_estimators = 1000,\n",
        "    learning_rate=0.001,\n",
        "    max_depth=3,\n",
        "    subsample=0.5,\n",
        "    gamma = 0.2,\n",
        "    colsample_bytree=0.5,\n",
        "    min_child_weight=1,\n",
        "    objective= 'binary:logistic',\n",
        "    scale_pos_weight=1,\n",
        "    seed=27)\n",
        "\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "grid_search = GridSearchCV(estimator=xgb1,\n",
        "                           param_grid=param_grid,\n",
        "                           cv=5,  # Use 5-fold cross-validation\n",
        "                           n_jobs=-1, # Use all available CPU cores\n",
        "                           scoring = 'f1')\n",
        "\n",
        "# Fit the grid search object to your training data\n",
        "grid_search.fit(x_train, y_train)\n",
        "\n",
        "# Best parameters found\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "\n",
        "# Best score (mean cross-validated score)\n",
        "print(\"Best Score:\", grid_search.best_score_)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Tune max_depth and min_child_weight\n",
        "We tune these first as they will have the highest impact on the model outcome.\n",
        "\n"
      ],
      "metadata": {
        "id": "v8fAgxxs3mDb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the hyperparameter grid\n",
        "param_grid = {\n",
        "    'max_depth':range(3,10,2),\n",
        "    'min_child_weight':range(1,6,2)\n",
        "}\n",
        "\n",
        "# Initialize Isolation Forest model\n",
        "xgb1 = XGBClassifier(\n",
        "    n_estimators = 900,\n",
        "    learning_rate=0.001,\n",
        "    max_depth=3,\n",
        "    subsample=0.5,\n",
        "    gamma = 0.2,\n",
        "    colsample_bytree=0.5,\n",
        "    min_child_weight=1,\n",
        "    objective= 'binary:logistic',\n",
        "    scale_pos_weight=1,\n",
        "    seed=27)\n",
        "\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "grid_search = GridSearchCV(estimator=xgb1,\n",
        "                           param_grid=param_grid,\n",
        "                           cv=5,  # Use 5-fold cross-validation\n",
        "                           n_jobs=-1, # Use all available CPU cores\n",
        "                           scoring = 'f1')\n",
        "\n",
        "# Fit the grid search object to your training data\n",
        "grid_search.fit(x_train, y_train)\n",
        "\n",
        "# Best parameters found\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "\n",
        "# Best score (mean cross-validated score)\n",
        "print(\"Best Score:\", grid_search.best_score_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AqbJ3tAQyedJ",
        "outputId": "3ecd9aaa-03bf-414e-c1c4-895c5f1246a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'max_depth': 9, 'min_child_weight': 1}\n",
            "Best Score: 0.9546134806529851\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1a54294c"
      },
      "source": [
        "##  Tune gamma\n",
        "\n",
        "\n",
        "Now let’s tune the gamma value using the parameters already tuned above.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the hyperparameter grid\n",
        "param_grid = {\n",
        "    'gamma':[i / 10.0 for i in range(5)],\n",
        "}\n",
        "\n",
        "# Initialize Isolation Forest model\n",
        "xgb1 = XGBClassifier(\n",
        "    n_estimators = 900,\n",
        "    learning_rate=0.001,\n",
        "    max_depth=9,\n",
        "    subsample=0.5,\n",
        "    gamma = 0.2,\n",
        "    colsample_bytree=0.5,\n",
        "    min_child_weight=1,\n",
        "    objective= 'binary:logistic',\n",
        "    scale_pos_weight=1,\n",
        "    seed=27)\n",
        "\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "grid_search = GridSearchCV(estimator=xgb1,\n",
        "                           param_grid=param_grid,\n",
        "                           cv=5,  # Use 5-fold cross-validation\n",
        "                           n_jobs=-1, # Use all available CPU cores\n",
        "                           scoring = 'f1')\n",
        "\n",
        "# Fit the grid search object to your training data\n",
        "grid_search.fit(x_train, y_train)\n",
        "\n",
        "# Best parameters found\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "\n",
        "# Best score (mean cross-validated score)\n",
        "print(\"Best Score:\", grid_search.best_score_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sdUEFibakmnh",
        "outputId": "a4c74bb5-a517-405d-ccac-0db1e5646a0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'gamma': 0.1}\n",
            "Best Score: 0.9546804073640821\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Tune subsample and colsample_bytree\n",
        "The next step would be to try different subsample and colsample_bytree values."
      ],
      "metadata": {
        "id": "-iGjeRZgpA2f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the hyperparameter grid\n",
        "param_grid = {\n",
        " 'subsample':[i/10.0 for i in range(6,10)],\n",
        " 'colsample_bytree':[i/10.0 for i in range(6,10)]\n",
        "}\n",
        "\n",
        "# Initialize Isolation Forest model\n",
        "xgb1 = XGBClassifier(\n",
        "    n_estimators = 900,\n",
        "    learning_rate=0.001,\n",
        "    max_depth=9,\n",
        "    subsample=0.5,\n",
        "    gamma = 0.1,\n",
        "    colsample_bytree=0.5,\n",
        "    min_child_weight=1,\n",
        "    objective= 'binary:logistic',\n",
        "    scale_pos_weight=1,\n",
        "    seed=27)\n",
        "\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "grid_search = GridSearchCV(estimator=xgb1,\n",
        "                           param_grid=param_grid,\n",
        "                           cv=5,  # Use 5-fold cross-validation\n",
        "                           n_jobs=-1, # Use all available CPU cores\n",
        "                           scoring = 'f1')\n",
        "\n",
        "# Fit the grid search object to your training data\n",
        "grid_search.fit(x_train, y_train)\n",
        "\n",
        "# Best parameters found\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "\n",
        "# Best score (mean cross-validated score)\n",
        "print(\"Best Score:\", grid_search.best_score_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTvufLt9oqxG",
        "outputId": "1725b4b3-8afe-4c62-f0e7-7191caaf60d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'colsample_bytree': 0.9, 'subsample': 0.9}\n",
            "Best Score: 0.9652468159846409\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Tune threshold\n",
        "\n",
        "The next step would be to find the best threshold selection using precision_recall_curve from scikit-learn library."
      ],
      "metadata": {
        "id": "WKzVQ-9VRAjM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_curve, f1_score\n",
        "\n",
        "\n",
        "xgb1 = XGBClassifier(\n",
        "n_estimators = 900,\n",
        "learning_rate=0.001,\n",
        "max_depth=9,\n",
        "subsample=0.9,\n",
        "gamma = 0.1,\n",
        "colsample_bytree=0.9,\n",
        "min_child_weight=1,\n",
        "objective= 'binary:logistic',\n",
        "scale_pos_weight=1,\n",
        "seed=27)\n",
        "\n",
        "\n",
        "xgb1.fit(x_train, y_train)\n",
        "probs = xgb1.predict_proba(x_test)[:, 1]   # probabilities for positive class\n",
        "\n",
        "precision, recall, thresholds = precision_recall_curve(y_test, probs)\n",
        "f1_scores = 2 * (precision * recall) / (precision + recall)\n",
        "best_idx = np.argmax(f1_scores)\n",
        "best_threshold = thresholds[best_idx]\n",
        "\n",
        "print(\"Best Threshold:\", best_threshold)\n",
        "print(\"Best F1 Score:\", f1_scores[best_idx])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2stt91xBmO2",
        "outputId": "5693ea2b-60ea-4103-d834-4964c4daf534"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Threshold: 0.28792283\n",
            "Best F1 Score: 0.970988082841606\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Full Results:\n",
        "\n",
        "here are the full results for the ML approach. Here we did the process 10 times using StratifiedShuffleSplit.\n",
        "\n",
        "##Final Results:\n",
        "\n",
        "Cross-Validation Results (10-fold avg):\n",
        "\n",
        "Accuracy: 0.9954\n",
        "\n",
        "Precision: 0.9922\n",
        "\n",
        "Recall: 0.9509\n",
        "\n",
        "F1 Score: 0.9711"
      ],
      "metadata": {
        "id": "dYdBoMTI1iSw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split,StratifiedShuffleSplit, GridSearchCV\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
        "import xgboost as xgb\n",
        "from xgboost.sklearn import XGBClassifier\n",
        "\n",
        "\n",
        "x = pd.read_csv(\"/content/drive/MyDrive/data/LMD-2023 [1.75M Elements][Labelled]checked.csv\",low_memory=False)\n",
        "\n",
        "cols = ['DestinationPortName','EventID','ThreadID','Computer','EventRecordID','Initiated',\n",
        "        'ProcessId','SourcePort', 'DestinationPort','Execution_ProcessID','Label']\n",
        "\n",
        "x = x[cols]\n",
        "\n",
        "y = x['Label'].copy()\n",
        "y = np.where(y > 0, 1, 0) # 1 means outlier\n",
        "\n",
        "x = x.drop(columns=['Label'])\n",
        "\n",
        "\n",
        "categorical_cols = ['Computer', 'DestinationPortName', 'EventID', 'Initiated']\n",
        "\n",
        "numerical_cols = ['EventRecordID','Execution_ProcessID', 'ProcessId','ThreadID','SourcePort','DestinationPort']\n",
        "\n",
        "skf = StratifiedShuffleSplit(n_splits=10, test_size=0.25, random_state=1)\n",
        "\n",
        "\n",
        "all_fold_metrics = []\n",
        "for i, (train_index, test_index) in enumerate(skf.split(x, y)):\n",
        "    x_train , x_test = x.iloc[train_index].copy(), x.iloc[test_index].copy()\n",
        "    y_train, y_test = y[train_index].copy(), y[test_index].copy()\n",
        "\n",
        "    if i + 1 == 10:\n",
        "      x_train_orig = x_train.copy()\n",
        "      x_test_orig = x_test.copy()\n",
        "\n",
        "    encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
        "    encoder.fit(x_train[categorical_cols])\n",
        "\n",
        "    x_train_categorial = pd.DataFrame(encoder.transform(x_train[categorical_cols]),\n",
        "                                    columns=encoder.get_feature_names_out(categorical_cols),\n",
        "                                    index=x_train.index)\n",
        "    x_test_categorial = pd.DataFrame(encoder.transform(x_test[categorical_cols]),\n",
        "                                    columns=encoder.get_feature_names_out(categorical_cols),\n",
        "                                    index=x_test.index)\n",
        "\n",
        "\n",
        "    #Scale numerical features with MinMaxScaler fit on train, then applying on val and test\n",
        "    scaler = MinMaxScaler()\n",
        "    scaler.fit(x_train[numerical_cols])\n",
        "\n",
        "    train_num_scaled = pd.DataFrame(scaler.transform(x_train[numerical_cols]), columns=numerical_cols, index=x_train.index)\n",
        "    test_num_scaled = pd.DataFrame(scaler.transform(x_test[numerical_cols]), columns=numerical_cols, index=x_test.index)\n",
        "\n",
        "\n",
        "    # Combine encoded categorical and scaled numerical features\n",
        "    x_train = pd.concat([x_train_categorial, train_num_scaled], axis=1)\n",
        "    x_test = pd.concat([x_test_categorial, test_num_scaled], axis=1)\n",
        "\n",
        "    xgb1 = XGBClassifier(\n",
        "    n_estimators = 900,\n",
        "    learning_rate=0.001,\n",
        "    max_depth=9,\n",
        "    subsample=0.9,\n",
        "    gamma = 0.1,\n",
        "    colsample_bytree=0.9,\n",
        "    min_child_weight=1,\n",
        "    objective= 'binary:logistic',\n",
        "    scale_pos_weight=1,\n",
        "    seed=27)\n",
        "\n",
        "\n",
        "    model = xgb1.fit(x_train, y_train)\n",
        "    probs = xgb1.predict_proba(x_test)[:, 1]   # probabilities for positive class\n",
        "\n",
        "    y_pred = (probs > 0.29).astype(int)\n",
        "    acc = metrics.accuracy_score(y_test, y_pred)\n",
        "    precision = metrics.precision_score(y_test, y_pred)\n",
        "    recall = metrics.recall_score(y_test, y_pred)\n",
        "    f1 = metrics.f1_score(y_test, y_pred)\n",
        "\n",
        "\n",
        "    print(f\"fold{i+1} results\")\n",
        "    print(f\"Accuracy: {acc:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print(f\"F1 Score: {f1:.4f}\\n\")\n",
        "    all_fold_metrics.append((acc, precision, recall, f1))\n",
        "\n",
        "results = np.array(all_fold_metrics)\n",
        "print(\"\\n Cross-Validation Results (10-fold avg):\")\n",
        "print(f\"Accuracy: {results[:,0].mean():.4f}\")\n",
        "print(f\"Precision: {results[:,1].mean():.4f}\")\n",
        "print(f\"Recall: {results[:,2].mean():.4f}\")\n",
        "print(f\"F1 Score: {results[:,3].mean():.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rq1JPv3T1YFz",
        "outputId": "dc340944-55c2-4cd1-dcec-2bd2849d297f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fold1 results\n",
            "Accuracy: 0.9955\n",
            "Precision: 0.9914\n",
            "Recall: 0.9518\n",
            "F1 Score: 0.9712\n",
            "\n",
            "fold2 results\n",
            "Accuracy: 0.9956\n",
            "Precision: 0.9920\n",
            "Recall: 0.9534\n",
            "F1 Score: 0.9724\n",
            "\n",
            "fold3 results\n",
            "Accuracy: 0.9955\n",
            "Precision: 0.9918\n",
            "Recall: 0.9526\n",
            "F1 Score: 0.9718\n",
            "\n",
            "fold4 results\n",
            "Accuracy: 0.9954\n",
            "Precision: 0.9920\n",
            "Recall: 0.9510\n",
            "F1 Score: 0.9711\n",
            "\n",
            "fold5 results\n",
            "Accuracy: 0.9955\n",
            "Precision: 0.9926\n",
            "Recall: 0.9510\n",
            "F1 Score: 0.9713\n",
            "\n",
            "fold6 results\n",
            "Accuracy: 0.9955\n",
            "Precision: 0.9931\n",
            "Recall: 0.9503\n",
            "F1 Score: 0.9712\n",
            "\n",
            "fold7 results\n",
            "Accuracy: 0.9956\n",
            "Precision: 0.9919\n",
            "Recall: 0.9526\n",
            "F1 Score: 0.9719\n",
            "\n",
            "fold8 results\n",
            "Accuracy: 0.9953\n",
            "Precision: 0.9935\n",
            "Recall: 0.9483\n",
            "F1 Score: 0.9704\n",
            "\n",
            "fold9 results\n",
            "Accuracy: 0.9955\n",
            "Precision: 0.9928\n",
            "Recall: 0.9510\n",
            "F1 Score: 0.9714\n",
            "\n",
            "fold10 results\n",
            "Accuracy: 0.9954\n",
            "Precision: 0.9919\n",
            "Recall: 0.9513\n",
            "F1 Score: 0.9712\n",
            "\n",
            "\n",
            " Cross-Validation Results (10-fold avg):\n",
            "Accuracy: 0.9955\n",
            "Precision: 0.9923\n",
            "Recall: 0.9513\n",
            "F1 Score: 0.9714\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we do FP and FN analyzing:"
      ],
      "metadata": {
        "id": "GNPTabkLgU5U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "FN = np.where((y_test == 1) & (y_pred == 0))[0]\n",
        "FP = np.where((y_test == 0) & (y_pred == 1))[0]\n",
        "\n",
        "fn_df = x_test_orig.iloc[FN].copy()\n",
        "fn_counts = fn_df[\"EventID\"].value_counts(normalize= True)\n",
        "print(fn_counts)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DD5pxv3xeZut",
        "outputId": "71cd1e06-59ba-4c87-8e69-2b99724a54db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EventID\n",
            "1     0.589535\n",
            "5     0.178488\n",
            "22    0.105233\n",
            "13    0.076163\n",
            "11    0.030814\n",
            "3     0.014535\n",
            "12    0.002326\n",
            "8     0.001163\n",
            "4     0.000581\n",
            "6     0.000581\n",
            "15    0.000581\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fn_df_1 = fn_df[fn_df['EventID'] == 1]\n",
        "display(fn_df_1[\"Computer\"].value_counts(normalize= True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "id": "fRwbXRighFJo",
        "outputId": "15d55004-47fa-4149-9ad5-50ab4e6fc9a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Computer\n",
              "WIN-J23NIGGP1Q6.sysmon_set.local    0.581854\n",
              "WINDOWS10EVAL.stefania.local        0.417160\n",
              "LAPTOP-ROPR18AK                     0.000986\n",
              "Name: proportion, dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>proportion</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Computer</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>WIN-J23NIGGP1Q6.sysmon_set.local</th>\n",
              "      <td>0.581854</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>WINDOWS10EVAL.stefania.local</th>\n",
              "      <td>0.417160</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LAPTOP-ROPR18AK</th>\n",
              "      <td>0.000986</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "fp_df = x_test_orig.iloc[FP].copy()\n",
        "fp_counts = fp_df[\"EventID\"].value_counts(normalize= True)\n",
        "print(fp_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2nXhkKriRfO",
        "outputId": "8f998729-587e-490e-a060-121d5a017c36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EventID\n",
            "1     0.509091\n",
            "3     0.461818\n",
            "5     0.021818\n",
            "13    0.003636\n",
            "22    0.003636\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fp_df_1 = fp_df[fp_df['EventID'] == 1]\n",
        "display(fp_df_1[\"Computer\"].value_counts(normalize= True))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "5D0PYle1k3Yp",
        "outputId": "70762e19-5ed8-41c9-d8c8-b8d32ccbdf64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Computer\n",
              "WIN-J23NIGGP1Q6.sysmon_set.local    0.907143\n",
              "WINDOWS10EVAL.stefania.local        0.092857\n",
              "Name: proportion, dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>proportion</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Computer</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>WIN-J23NIGGP1Q6.sysmon_set.local</th>\n",
              "      <td>0.907143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>WINDOWS10EVAL.stefania.local</th>\n",
              "      <td>0.092857</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('FP ThreadID proportion\\n')\n",
        "\n",
        "display(fp_df_1[\"ThreadID\"].value_counts(normalize= True))\n",
        "\n",
        "print('FN ThreadID proportion\\n')\n",
        "\n",
        "display(fn_df_1[\"ThreadID\"].value_counts(normalize= True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fiNDazpLiWvu",
        "outputId": "c1397c8e-fb6a-44ed-950a-4a6dc6c420e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FN ThreadID proportion\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "ThreadID\n",
              "1292    0.392857\n",
              "3408    0.278571\n",
              "1912    0.207143\n",
              "3016    0.042857\n",
              "3724    0.028571\n",
              "3324    0.021429\n",
              "3184    0.014286\n",
              "3340    0.007143\n",
              "836     0.007143\n",
              "Name: proportion, dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>proportion</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ThreadID</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1292</th>\n",
              "      <td>0.392857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3408</th>\n",
              "      <td>0.278571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1912</th>\n",
              "      <td>0.207143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3016</th>\n",
              "      <td>0.042857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3724</th>\n",
              "      <td>0.028571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3324</th>\n",
              "      <td>0.021429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3184</th>\n",
              "      <td>0.014286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3340</th>\n",
              "      <td>0.007143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>836</th>\n",
              "      <td>0.007143</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FP ThreadID proportion\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "ThreadID\n",
              "1912    0.133136\n",
              "1508    0.119329\n",
              "1292    0.108481\n",
              "5084    0.088757\n",
              "3408    0.055227\n",
              "2992    0.044379\n",
              "3184    0.036489\n",
              "2560    0.032544\n",
              "3280    0.030572\n",
              "2912    0.025641\n",
              "3844    0.025641\n",
              "2492    0.022682\n",
              "3120    0.022682\n",
              "3764    0.021696\n",
              "2940    0.013807\n",
              "2876    0.013807\n",
              "2956    0.013807\n",
              "3416    0.011834\n",
              "2952    0.011834\n",
              "2164    0.011834\n",
              "2408    0.009862\n",
              "980     0.009862\n",
              "792     0.008876\n",
              "3004    0.008876\n",
              "3800    0.007890\n",
              "1048    0.007890\n",
              "3076    0.007890\n",
              "3016    0.006903\n",
              "1856    0.006903\n",
              "3420    0.006903\n",
              "3328    0.006903\n",
              "3596    0.005917\n",
              "3260    0.005917\n",
              "636     0.005917\n",
              "2968    0.004931\n",
              "3324    0.004931\n",
              "3080    0.004931\n",
              "716     0.003945\n",
              "3048    0.003945\n",
              "2632    0.003945\n",
              "3008    0.003945\n",
              "3748    0.003945\n",
              "836     0.002959\n",
              "3116    0.002959\n",
              "6112    0.001972\n",
              "388     0.001972\n",
              "2848    0.001972\n",
              "3340    0.000986\n",
              "2896    0.000986\n",
              "6840    0.000986\n",
              "Name: proportion, dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>proportion</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ThreadID</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1912</th>\n",
              "      <td>0.133136</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1508</th>\n",
              "      <td>0.119329</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1292</th>\n",
              "      <td>0.108481</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5084</th>\n",
              "      <td>0.088757</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3408</th>\n",
              "      <td>0.055227</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2992</th>\n",
              "      <td>0.044379</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3184</th>\n",
              "      <td>0.036489</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2560</th>\n",
              "      <td>0.032544</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3280</th>\n",
              "      <td>0.030572</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2912</th>\n",
              "      <td>0.025641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3844</th>\n",
              "      <td>0.025641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2492</th>\n",
              "      <td>0.022682</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3120</th>\n",
              "      <td>0.022682</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3764</th>\n",
              "      <td>0.021696</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2940</th>\n",
              "      <td>0.013807</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2876</th>\n",
              "      <td>0.013807</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2956</th>\n",
              "      <td>0.013807</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3416</th>\n",
              "      <td>0.011834</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2952</th>\n",
              "      <td>0.011834</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2164</th>\n",
              "      <td>0.011834</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2408</th>\n",
              "      <td>0.009862</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>980</th>\n",
              "      <td>0.009862</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>792</th>\n",
              "      <td>0.008876</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3004</th>\n",
              "      <td>0.008876</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3800</th>\n",
              "      <td>0.007890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1048</th>\n",
              "      <td>0.007890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3076</th>\n",
              "      <td>0.007890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3016</th>\n",
              "      <td>0.006903</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1856</th>\n",
              "      <td>0.006903</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3420</th>\n",
              "      <td>0.006903</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3328</th>\n",
              "      <td>0.006903</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3596</th>\n",
              "      <td>0.005917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3260</th>\n",
              "      <td>0.005917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>636</th>\n",
              "      <td>0.005917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2968</th>\n",
              "      <td>0.004931</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3324</th>\n",
              "      <td>0.004931</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3080</th>\n",
              "      <td>0.004931</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>716</th>\n",
              "      <td>0.003945</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3048</th>\n",
              "      <td>0.003945</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2632</th>\n",
              "      <td>0.003945</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3008</th>\n",
              "      <td>0.003945</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3748</th>\n",
              "      <td>0.003945</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>836</th>\n",
              "      <td>0.002959</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3116</th>\n",
              "      <td>0.002959</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6112</th>\n",
              "      <td>0.001972</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>388</th>\n",
              "      <td>0.001972</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2848</th>\n",
              "      <td>0.001972</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3340</th>\n",
              "      <td>0.000986</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2896</th>\n",
              "      <td>0.000986</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6840</th>\n",
              "      <td>0.000986</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "L4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}